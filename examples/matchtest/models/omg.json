{
    "kind": "openai",
    "api_key": "$OMG_API_KEY",
    "base_url": "https://api.ohmygpt.com/v1",
    "models": [
        {
            "name": "omg/gpt-4o-mini",
            "model": "gpt-4o-mini",
            "support_json_output": true,
            "support_text_only": true,
            "use_system_role": true,
            "generate_params": {
                "max_tokens": 4096,
                "temperature": 1,
                "top_p": 1
            },
            "invoke_params": {
                "max_tokens": 4096,
                "temperature": 0.1,
                "top_p": 1
            }
        },
        {
            "name": "omg/gpt-4o",
            "model": "gpt-4o",
            "support_json_output": true,
            "support_text_only": true,
            "use_system_role": true,
            "generate_params": {
                "max_tokens": 4096,
                "temperature": 1,
                "top_p": 1
            },
            "invoke_params": {
                "max_tokens": 4096,
                "temperature": 0.1,
                "top_p": 1
            }
        },
        {
            "name": "omg/claude-3.5-sonnet",
            "model": "claude-3-5-sonnet-20241022",
            "support_json_output": true,
            "support_text_only": true,
            "use_system_role": true,
            "generate_params": {
                "max_tokens": 4096,
                "temperature": 1,
                "top_p": 1
            },
            "invoke_params": {
                "max_tokens": 4096,
                "temperature": 0.1,
                "top_p": 1
            }
        },
        {
            "name": "omg/claude-3.5-haiku",
            "model": "claude-3-5-haiku-20241022",
            "support_json_output": true,
            "support_text_only": true,
            "use_system_role": true,
            "generate_params": {
                "max_tokens": 4096,
                "temperature": 1,
                "top_p": 1
            },
            "invoke_params": {
                "max_tokens": 4096,
                "temperature": 0.1,
                "top_p": 1
            }
        }
    ]
}
